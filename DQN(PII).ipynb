{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heinsburg123/Chatbot/blob/main/DQN(PII).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "j9xhaRfuSJen"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "from random import choice\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "35CZbbSYTI2T"
      },
      "outputs": [],
      "source": [
        "Transition=namedtuple(\"Transition\",(\"state\",\"action\",\"reward\",\"nx_state\"))\n",
        "class Replay:\n",
        "  def __init__(self,size):\n",
        "    self.mem=deque([],maxlen=size)\n",
        "  def push(self,*arg):\n",
        "    self.mem.append(Transition(*arg))\n",
        "  def get(self,batch_size):\n",
        "    return random.sample(self.mem,batch_size)\n",
        "  def get_index(self,index):\n",
        "    return self.mem[index]\n",
        "  def len(self):\n",
        "    return len(self.mem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_6eTveA7TJjJ"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "  def __init__(self,n_observations,n_actions):\n",
        "    super(DQN,self).__init__()\n",
        "    self.layer1=nn.Linear(n_observations,400)\n",
        "    self.layer2=nn.Linear(400,400)\n",
        "    self.layer3=nn.Linear(400,n_actions)\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.layer1(x))\n",
        "    x=F.relu(self.layer2(x))\n",
        "    return self.layer3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NDNSgBDr3J-j"
      },
      "outputs": [],
      "source": [
        "ANSWER=[(2,2),(9,2),(16,2),(2,9),(9,9),(16,9),(2,16),(9,16),()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KgD0AZnUTLJt"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=80\n",
        "eps_st=1\n",
        "eps_en=0.1\n",
        "eps_decay=600\n",
        "gamma=0.99\n",
        "TAU=0.005\n",
        "LR=0.001\n",
        "n_actions=4\n",
        "n_para=3\n",
        "n_behind=5\n",
        "expo=2\n",
        "state=torch.tensor([])\n",
        "n_obs=len(state)\n",
        "policy=DQN(n_para*n_behind,n_actions).to(device)\n",
        "target=DQN(n_para*n_behind,n_actions).to(device)\n",
        "opti=optim.AdamW(policy.parameters(),lr=LR,amsgrad=True)\n",
        "memory=Replay(10000)\n",
        "step=0\n",
        "turn=0\n",
        "actions=([0,1],[1,0],[0,-1],[-1,0])\n",
        "\n",
        "\n",
        "def select(state,cur_loc,turn,step):\n",
        "  sample=random.random()\n",
        "  eps_threshold=eps_en+(eps_st-eps_en)*math.exp(-1*step/eps_decay)\n",
        "  lst=[]\n",
        "  mask=[1,1,1,1]\n",
        "  if(cur_loc[0]==19):\n",
        "    mask[1]=0\n",
        "  if(cur_loc[1]==19):\n",
        "    mask[0]=0\n",
        "  if(cur_loc[0]==0):\n",
        "    mask[3]=0\n",
        "  if(cur_loc[1]==0):\n",
        "    mask[2]=0\n",
        "  for i in range(4):\n",
        "    if(mask[i]==1):\n",
        "      lst.append(i)\n",
        "  if(sample<=eps_threshold or turn<=10):\n",
        "    return torch.tensor([[random.choice(lst)]], device=device,dtype=torch.long)\n",
        "  else:\n",
        "    val=policy(state)[0,lst].max(-1)[1]\n",
        "    num=torch.tensor(lst[val.item()],device=device).view(1,1)\n",
        "    return num\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5_yJN1t6TN3Q"
      },
      "outputs": [],
      "source": [
        "def optimize():\n",
        "  if memory.len()<BATCH_SIZE:\n",
        "    return\n",
        "  transitions=memory.get(BATCH_SIZE)\n",
        "  batch=Transition(*zip(*transitions))\n",
        "  nx_state_batch=torch.cat(batch.nx_state)\n",
        "  state_batch=torch.cat(batch.state)\n",
        "  action_batch=torch.cat(batch.action)\n",
        "  reward_batch=torch.cat(batch.reward)\n",
        "  state_action_values=policy(state_batch).gather(1,action_batch)\n",
        "  with torch.no_grad():\n",
        "    nx_state_values=target(nx_state_batch).max(1)[0].unsqueeze(1)\n",
        "  expect=nx_state_values*gamma+reward_batch.unsqueeze(1)\n",
        "  crit=nn.SmoothL1Loss()\n",
        "  loss=crit(state_action_values,expect)\n",
        "  opti.zero_grad()\n",
        "  loss.backward()\n",
        "  torch.nn.utils.clip_grad_value_(policy.parameters(), 100)\n",
        "  opti.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "MxIjz-IlTQWg"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  num_episodes = 1000\n",
        "else:\n",
        "  num_episodes = 1000\n",
        "def training(map):\n",
        "  step=0\n",
        "  eps_st=0.9\n",
        "  eps_en=0.1\n",
        "  ans=np.max(map)\n",
        "  dem=0\n",
        "  for i in range(num_episodes):\n",
        "    cur_loc=[19,0]\n",
        "    state=torch.tensor([[]])\n",
        "    state=torch.tensor(state,dtype=torch.float32,device=device).unsqueeze(0)\n",
        "    check=np.zeros((20,20))\n",
        "    turn=-1\n",
        "    for zz in range(1600):\n",
        "      turn=turn+1\n",
        "      step=step+1\n",
        "      action=select(state,cur_loc,turn,step)\n",
        "      nx_loc=np.array(actions[action])+cur_loc\n",
        "      passed=check[tuple(nx_loc)]\n",
        "      reward=map[tuple(nx_loc)]-map[tuple(cur_loc)]-passed**2\n",
        "      if(map[tuple(nx_loc)]==ans):\n",
        "        reward=1e9-passed**2\n",
        "      reward = torch.tensor([reward], device=device)\n",
        "      pf=[map[tuple(nx_loc)]-map[tuple(cur_loc)],action,passed]\n",
        "      nx_pos=torch.tensor([pf],dtype=torch.float32,device=device)\n",
        "      if(turn>0):\n",
        "        nx_state=torch.cat((state,nx_pos),-1)\n",
        "      else:\n",
        "        nx_state=torch.clone(nx_pos)\n",
        "      if(nx_state.size()[1]==n_para*(n_behind+1)):\n",
        "        nx_state=torch.clone(nx_state[:,n_para:])\n",
        "      if(state.size()[1]==n_para*n_behind):\n",
        "        memory.push(state,action,reward,nx_state)\n",
        "      check[tuple(cur_loc)]=check[tuple(cur_loc)]+1\n",
        "      cur_loc=nx_loc\n",
        "      state=torch.clone(nx_state)\n",
        "      optimize()\n",
        "      target_net_state_dict = target.state_dict()\n",
        "      policy_net_state_dict = policy.state_dict()\n",
        "      for key in policy_net_state_dict:\n",
        "          target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
        "      target.load_state_dict(target_net_state_dict)\n",
        "      if(map[tuple(nx_loc)]==ans):\n",
        "        print(dem)\n",
        "        dem=dem+1\n",
        "        break\n",
        "  print(dem)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YrxAr6R5Vr8f"
      },
      "outputs": [],
      "source": [
        "def testing(map):\n",
        "  ans=np.max(map)\n",
        "  state=torch.tensor([[]])\n",
        "  state=torch.tensor(state,dtype=torch.float32,device=device).unsqueeze(0)\n",
        "  check=np.zeros((20,20))\n",
        "  cur_loc=np.array([19,0])\n",
        "  ans=np.max(map)\n",
        "  turn=-1\n",
        "  for i in range(400):\n",
        "    turn=turn+1\n",
        "    action=select(state,cur_loc,turn,1e9)\n",
        "    nx_loc=np.array(actions[action])+cur_loc\n",
        "    if(map[tuple(nx_loc)]==ans):\n",
        "      return turn\n",
        "    passed=check[tuple(nx_loc)]\n",
        "    pf=[map[tuple(nx_loc)]-map[tuple(cur_loc)],action,passed]\n",
        "    nx_pos=torch.tensor([pf],dtype=torch.float32,device=device)\n",
        "    if(turn>0):\n",
        "      nx_state=torch.cat((state,nx_pos),-1)\n",
        "    else:\n",
        "      nx_state=torch.clone(nx_pos)\n",
        "    if(nx_state.size()[1]==n_para*(n_behind+1)):\n",
        "      nx_state=torch.clone(nx_state[:,n_para:])\n",
        "    check[tuple(cur_loc)]=check[tuple(cur_loc)]+1\n",
        "    cur_loc=nx_loc\n",
        "    state=torch.clone(nx_state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5gZ6g9QWXBdR",
        "outputId": "f7ca6046-3269-4c5e-ba90-b16e45fa3b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-b29db5f71e26>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  state=torch.tensor(state,dtype=torch.float32,device=device).unsqueeze(0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-2005a697bec4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-b29db5f71e26>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mcur_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnx_loc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m       \u001b[0mtarget_net_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mpolicy_net_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-f544435d000c>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mopti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    169\u001b[0m             )\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m                 \u001b[0;31m# Use the max. for normalizing running avg. of gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i in range(1,2):\n",
        "  board=(f'wall_1_{i}.csv')\n",
        "  map=np.loadtxt(board,delimiter=',')\n",
        "  for j in range(0,20):\n",
        "    for z in range(0,20):\n",
        "        map[j,z]=map[j,z]*10**7\n",
        "        map[j,z]=map[j,z]**2\n",
        "  training(map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC_ODgz5qpY9"
      },
      "outputs": [],
      "source": [
        "for i in range(1,10):\n",
        "  board=(f'wall_1_{i}.csv')\n",
        "  map=np.loadtxt(board,delimiter=',')\n",
        "  for j in range(0,20):\n",
        "    for z in range(0,20):\n",
        "        map[j,z]=map[j,z]*10**7\n",
        "        map[j,z]=map[j,z]**2\n",
        "  print(testing(map))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOl9k/LzxzCtPM0/fQucLh2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}